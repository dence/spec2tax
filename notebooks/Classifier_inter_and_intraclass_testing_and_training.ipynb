{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c06aa8ad",
   "metadata": {},
   "source": [
    "# Spec2Tax: Prediction Sample Taxonomy from MS/MS Spectra \n",
    "## Training and testing a logist regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dd81cc",
   "metadata": {},
   "source": [
    "First defining functions that do the trainig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16968f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_l1_ratios():\n",
    "    \"\"\"Return a list of values that are used by the elastic net as hyperparameters.\"\"\"\n",
    "    return [\n",
    "        i / 100\n",
    "        for i in range(0, 101)\n",
    "        if not _skip_index(i)\n",
    "    ]\n",
    "\n",
    "\n",
    "def _skip_index(i):\n",
    "    return (i < 70 and (i % 2) == 0) or ((i % 3) == 0) or ((i % 5) == 0)\n",
    "\n",
    "\n",
    "def train_elastic_net_model(\n",
    "    x,\n",
    "    y,\n",
    "    outer_cv_splits: int,\n",
    "    inner_cv_splits: int,\n",
    "    l1_ratio: List[float],\n",
    "    max_iter: Optional[int] = None,\n",
    "):\n",
    "    \"\"\"Train elastic net model via a nested cross validation given expression data.\n",
    "    Uses a defined hyperparameter space for l1_ratio.\n",
    "    :param numpy.array x: 2D matrix of pathway scores and samples\n",
    "    :param list y: class labels of samples\n",
    "    :param outer_cv_splits: number of folds for cross validation split in outer loop\n",
    "    :param inner_cv_splits: number of folds for cross validation split in inner loop\n",
    "    :param l1_ratio: list of hyper-parameters for l1 and l2 priors\n",
    "    :param model_name: name of the model\n",
    "    :param max_iter: default to 1000 to ensure convergence\n",
    "    :param export: Export the models using :mod:`joblib`\n",
    "    :return: A list of AUC-ROC scores\n",
    "    \"\"\"\n",
    "\n",
    "    test_info = []\n",
    "    auc_scores = []\n",
    "    f1_scores = []\n",
    "    recall_scores = []\n",
    "\n",
    "    it = _help_train_elastic_net_model(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        outer_cv_splits=outer_cv_splits,\n",
    "        inner_cv_splits=inner_cv_splits,\n",
    "        l1_ratio=l1_ratio,\n",
    "        max_iter=max_iter,\n",
    "    )\n",
    "\n",
    "    # Iterator to calculate metrics for each CV step\n",
    "    for i, (glm_elastic, y_test, y_pred, y_prob) in enumerate(it):\n",
    "        # auc_scores.append(roc_auc_score(y_test, y_prob, multi_class='ovr'))\n",
    "        f1_scores.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "        recall_scores.append(recall_score(y_test, y_pred, average='weighted'))\n",
    "        test_info.append({\n",
    "            \"test_classes\": dict(Counter(y_test)),\n",
    "            \"predicted_classes\": dict(Counter(y_pred))\n",
    "        })\n",
    "\n",
    "    # Return a list with all AUC/AUC-PR scores for each CV step    \n",
    "    return auc_scores, f1_scores, recall_scores, test_info\n",
    "\n",
    "\n",
    "def _help_train_elastic_net_model(\n",
    "    x,\n",
    "    y,\n",
    "    outer_cv_splits: int,\n",
    "    inner_cv_splits: int,\n",
    "    l1_ratio: Union[float, List[float]],\n",
    "    max_iter: Optional[int] = None,\n",
    "):\n",
    "    max_iter = max_iter or 1000\n",
    "    # Use variation of KFold cross validation that returns stratified folds for outer loop in the CV.\n",
    "    # The folds are made by preserving the percentage of samples for each class.\n",
    "    skf = StratifiedKFold(n_splits=outer_cv_splits, shuffle=True)\n",
    "\n",
    "    # tqdm wrapper to print the current CV state\n",
    "    iterator = tqdm(skf.split(x, y), desc='Outer CV for classification', total=outer_cv_splits)\n",
    "\n",
    "    # Parameter Grid\n",
    "    param_grid = dict(l1_ratio=l1_ratio)\n",
    "\n",
    "    for train_indexes, test_indexes in iterator:\n",
    "        # Splice the entire data set so only the training and test sets for this CV iter are used\n",
    "        x_train, x_test = x[train_indexes], x[test_indexes]\n",
    "        y_train = [y[train_index] for train_index in train_indexes]\n",
    "        y_test = [y[test_index] for test_index in test_indexes]\n",
    "\n",
    "        # Instantiate the model fitting along a regularization path (CV).\n",
    "        # Inner loop\n",
    "        estimator = linear_model.LogisticRegression(\n",
    "            penalty='elasticnet',\n",
    "            class_weight='balanced',\n",
    "            solver='saga',\n",
    "            multi_class='multinomial',\n",
    "            max_iter=max_iter,\n",
    "            C=1,\n",
    "        )\n",
    "\n",
    "        glm_elastic = model_selection.GridSearchCV(\n",
    "            estimator=estimator,\n",
    "            param_grid=param_grid,\n",
    "            cv=inner_cv_splits,\n",
    "            scoring='roc_auc_ovo_weighted',\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "\n",
    "        # Fit model with train data\n",
    "        glm_elastic.fit(x_train, y_train)\n",
    "\n",
    "        # Predict trained model with test data\n",
    "        y_prob = glm_elastic.predict_proba(x_test)\n",
    "        y_pred = glm_elastic.predict(x_test)\n",
    "\n",
    "        # Return model and y test y predict to calculate prediction metrics\n",
    "        yield glm_elastic, y_test, y_pred, y_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c15f3e9",
   "metadata": {},
   "source": [
    "## Interclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c136f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "local_input_directory = \"spec2tax\"\n",
    "input_directory = f\"{local_input_directory}/class\"\n",
    "logger.info(f'Starting spec2fam')\n",
    "X = pickle.load(open(f\"{input_directory}/X.pkl\", 'rb'))\n",
    "y = pickle.load(open(f\"{input_directory}/y.pkl\", 'rb'))\n",
    "logger.info(f'loaded X and y')\n",
    "logger.info(Counter(y))\n",
    "\n",
    "output_directory = f\"{input_directory}/results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a541f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_cv_splits = 5\n",
    "inner_cv_splits = 5\n",
    "\n",
    "# TODO: Remove later. Uncomment this line to do the permuted test\n",
    "# np.random.shuffle(y_with_ints)\n",
    "\n",
    "max_iter = 1000\n",
    "\n",
    "this_auc_scores, this_f1s, this_recalls, this_class_info = train_elastic_net_model(\n",
    "    X,\n",
    "    y_with_ints,\n",
    "    outer_cv_splits,\n",
    "    inner_cv_splits,\n",
    "    get_l1_ratios(),\n",
    "    max_iter,\n",
    ")\n",
    "minutes = (time.time() - start_time) / 60.0\n",
    "logger.info(f'Embedding finished after {minutes:.2f} minutes')\n",
    "logger.info(\"model trained, congrats!\")\n",
    "\n",
    "logger.info('here is the auc performacnce')\n",
    "logger.info(this_auc_scores)\n",
    "logger.info('here is the f1 performance')\n",
    "logger.info(this_f1s)\n",
    "logger.info('here is the recall performance')\n",
    "logger.info(this_recalls)\n",
    "logger.info('here is the class information')\n",
    "logger.info(this_class_info)\n",
    "performance_metrics = {\n",
    "    \"AUC\": this_auc_scores,\n",
    "    \"F1\": this_f1s,\n",
    "    \"recall\": this_recalls,\n",
    "    \"classes\": this_class_info,\n",
    "}\n",
    "metrics_json = json.dumps(performance_metrics)\n",
    "with open(f\"{output_directory}/metrics.json\", 'w') as outfile:\n",
    "    outfile.write(metrics_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeb162e",
   "metadata": {},
   "source": [
    "## Intra-mammalia Classificiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3893e5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "local_input_directory = \"spec2tax\"\n",
    "input_directory = f\"{local_input_directory}/class\"\n",
    "\n",
    "logger.info(f'Starting spec2fam')\n",
    "X = pickle.load(open(f\"{input_directory}/X.pkl\", 'rb'))\n",
    "y = pickle.load(open(f\"{input_directory}/y.pkl\", 'rb'))\n",
    "logger.info(f'loaded X and y')\n",
    "logger.info(Counter(y))\n",
    "\n",
    "output_directory = f\"{input_directory}/results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f9b1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_cv_splits = 5\n",
    "inner_cv_splits = 5\n",
    "\n",
    "# TODO: Remove later. Uncomment this line to do the permuted test\n",
    "# np.random.shuffle(y_with_ints)\n",
    "\n",
    "max_iter = 1000\n",
    "\n",
    "this_auc_scores, this_f1s, this_recalls, this_class_info = train_elastic_net_model(\n",
    "    X,\n",
    "    y_with_ints,\n",
    "    outer_cv_splits,\n",
    "    inner_cv_splits,\n",
    "    get_l1_ratios(),\n",
    "    max_iter,\n",
    ")\n",
    "minutes = (time.time() - start_time) / 60.0\n",
    "logger.info(f'Embedding finished after {minutes:.2f} minutes')\n",
    "logger.info(\"model trained, congrats!\")\n",
    "\n",
    "logger.info('here is the auc performacnce')\n",
    "logger.info(this_auc_scores)\n",
    "logger.info('here is the f1 performance')\n",
    "logger.info(this_f1s)\n",
    "logger.info('here is the recall performance')\n",
    "logger.info(this_recalls)\n",
    "logger.info('here is the class information')\n",
    "logger.info(this_class_info)\n",
    "performance_metrics = {\n",
    "    \"AUC\": this_auc_scores,\n",
    "    \"F1\": this_f1s,\n",
    "    \"recall\": this_recalls,\n",
    "    \"classes\": this_class_info,\n",
    "}\n",
    "metrics_json = json.dumps(performance_metrics)\n",
    "with open(f\"{output_directory}/metrics.json\", 'w') as outfile:\n",
    "    outfile.write(metrics_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45af2ba1",
   "metadata": {},
   "source": [
    "## Intra-magnoliopsida Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1944053c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "local_input_directory = \"spec2tax\"\n",
    "input_directory = f\"{local_input_directory}/class\"\n",
    "\n",
    "logger.info(f'Starting spec2fam')\n",
    "X = pickle.load(open(f\"{input_directory}/X.pkl\", 'rb'))\n",
    "y = pickle.load(open(f\"{input_directory}/y.pkl\", 'rb'))\n",
    "logger.info(f'loaded X and y')\n",
    "logger.info(Counter(y))\n",
    "\n",
    "output_directory = f\"{input_directory}/results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdc56a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_cv_splits = 5\n",
    "inner_cv_splits = 5\n",
    "\n",
    "# TODO: Remove later. Uncomment this line to do the permuted test\n",
    "# np.random.shuffle(y_with_ints)\n",
    "\n",
    "max_iter = 1000\n",
    "\n",
    "this_auc_scores, this_f1s, this_recalls, this_class_info = train_elastic_net_model(\n",
    "    X,\n",
    "    y_with_ints,\n",
    "    outer_cv_splits,\n",
    "    inner_cv_splits,\n",
    "    get_l1_ratios(),\n",
    "    max_iter,\n",
    ")\n",
    "minutes = (time.time() - start_time) / 60.0\n",
    "logger.info(f'Embedding finished after {minutes:.2f} minutes')\n",
    "logger.info(\"model trained, congrats!\")\n",
    "\n",
    "logger.info('here is the auc performacnce')\n",
    "logger.info(this_auc_scores)\n",
    "logger.info('here is the f1 performance')\n",
    "logger.info(this_f1s)\n",
    "logger.info('here is the recall performance')\n",
    "logger.info(this_recalls)\n",
    "logger.info('here is the class information')\n",
    "logger.info(this_class_info)\n",
    "performance_metrics = {\n",
    "    \"AUC\": this_auc_scores,\n",
    "    \"F1\": this_f1s,\n",
    "    \"recall\": this_recalls,\n",
    "    \"classes\": this_class_info,\n",
    "}\n",
    "metrics_json = json.dumps(performance_metrics)\n",
    "with open(f\"{output_directory}/metrics.json\", 'w') as outfile:\n",
    "    outfile.write(metrics_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae3faa3",
   "metadata": {},
   "source": [
    "## Intra-gammaproteobactera Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1098b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "local_input_directory = \"spec2tax\"\n",
    "input_directory = f\"{local_input_directory}/class\"\n",
    "\n",
    "logger.info(f'Starting spec2fam')\n",
    "X = pickle.load(open(f\"{input_directory}/X.pkl\", 'rb'))\n",
    "y = pickle.load(open(f\"{input_directory}/y.pkl\", 'rb'))\n",
    "logger.info(f'loaded X and y')\n",
    "logger.info(Counter(y))\n",
    "\n",
    "output_directory = f\"{input_directory}/results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85aba44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_cv_splits = 5\n",
    "inner_cv_splits = 5\n",
    "\n",
    "# TODO: Remove later. Uncomment this line to do the permuted test\n",
    "# np.random.shuffle(y_with_ints)\n",
    "\n",
    "max_iter = 1000\n",
    "\n",
    "this_auc_scores, this_f1s, this_recalls, this_class_info = train_elastic_net_model(\n",
    "    X,\n",
    "    y_with_ints,\n",
    "    outer_cv_splits,\n",
    "    inner_cv_splits,\n",
    "    get_l1_ratios(),\n",
    "    max_iter,\n",
    ")\n",
    "minutes = (time.time() - start_time) / 60.0\n",
    "logger.info(f'Embedding finished after {minutes:.2f} minutes')\n",
    "logger.info(\"model trained, congrats!\")\n",
    "\n",
    "logger.info('here is the auc performacnce')\n",
    "logger.info(this_auc_scores)\n",
    "logger.info('here is the f1 performance')\n",
    "logger.info(this_f1s)\n",
    "logger.info('here is the recall performance')\n",
    "logger.info(this_recalls)\n",
    "logger.info('here is the class information')\n",
    "logger.info(this_class_info)\n",
    "performance_metrics = {\n",
    "    \"AUC\": this_auc_scores,\n",
    "    \"F1\": this_f1s,\n",
    "    \"recall\": this_recalls,\n",
    "    \"classes\": this_class_info,\n",
    "}\n",
    "metrics_json = json.dumps(performance_metrics)\n",
    "with open(f\"{output_directory}/metrics.json\", 'w') as outfile:\n",
    "    outfile.write(metrics_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
